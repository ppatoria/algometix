<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>CPU Cache: Organization, Optimization and Challenges on Algometix</title>
    <link>http://localhost:46239/blog/cpu_cache/</link>
    <description>Recent content in CPU Cache: Organization, Optimization and Challenges on Algometix</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Jan 0001 00:00:00 +0000</lastBuildDate>
    <atom:link href="http://localhost:46239/blog/cpu_cache/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>http://localhost:46239/blog/cpu_cache/singlecore-caching/cache_coherence/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:46239/blog/cpu_cache/singlecore-caching/cache_coherence/</guid>
      <description>&lt;h1 id=&#34;load-and-store-buffers&#34;&gt;&#xA;  Load and Store Buffers&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#load-and-store-buffers&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h1&gt;&#xA;&lt;h3 id=&#34;understanding-write-buffering-in-a-non-coherent-shared-cache&#34;&gt;&#xA;  &lt;strong&gt;Understanding Write Buffering in a Non-Coherent Shared Cache&lt;/strong&gt;&#xA;  &lt;a class=&#34;anchor&#34; href=&#34;#understanding-write-buffering-in-a-non-coherent-shared-cache&#34;&gt;#&lt;/a&gt;&#xA;&lt;/h3&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;CPU Write Path:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;When a thread writes to memory, the CPU &lt;strong&gt;does not&lt;/strong&gt; always update the cache/memory immediately.&lt;/li&gt;&#xA;&lt;li&gt;Instead, the data may first go into a &lt;strong&gt;store buffer (write buffer)&lt;/strong&gt; inside the CPU.&lt;/li&gt;&#xA;&lt;li&gt;This buffer temporarily holds the write before it gets committed to the L1 cache.&lt;/li&gt;&#xA;&lt;li&gt;This delay causes another thread reading the same memory location to observe stale data, as the update isn&amp;rsquo;t immediately visible in the cache.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;&#xA;&lt;p&gt;&lt;strong&gt;CPU Read Path:&lt;/strong&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:46239/blog/cpu_cache/singlecore-caching/gemini_singlecore_multicore/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:46239/blog/cpu_cache/singlecore-caching/gemini_singlecore_multicore/</guid>
      <description>&lt;p&gt;please review for correctness &amp;ldquo;## Cache Coherence and Protocols: Ensuring Data Consistency in Multi-Core Systems&#xA;Modern multi -  core processors rely on private caches to reduce latency and improve performance.However, when multiple cores access the same memory location, ensuring consistency across caches becomes essential. Cache coherence guarantees that all cores observe a consistent view of memory, preventing stale or incorrect data from affecting computations.&lt;/p&gt;&#xA;&lt;p&gt;This article explores why cache coherence is crucial, common problems that arise without it,and how protocols address these issues.&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:46239/blog/cpu_cache/singlecore-caching/reordeing/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:46239/blog/cpu_cache/singlecore-caching/reordeing/</guid>
      <description>&lt;p&gt;Reordering issues occurs in single-core machines with multiple threads. It&amp;rsquo;s a common misconception that multi-core systems are a prerequisite for reordering problems. While the &lt;em&gt;consequences&lt;/em&gt; of reordering might be more dramatic in multi-core systems (due to cache coherence complexities), the &lt;em&gt;root cause&lt;/em&gt; – compiler and CPU optimizations – exists even in single-core environments.&lt;/p&gt;&#xA;&lt;p&gt;&lt;strong&gt;How Reordering Occurs in a Single-Core System:&lt;/strong&gt;&lt;/p&gt;&#xA;&lt;p&gt;Even though there&amp;rsquo;s only one core executing instructions, the compiler and the CPU can still reorder memory operations. Here&amp;rsquo;s why:&lt;/p&gt;</description>
    </item>
    <item>
      <title></title>
      <link>http://localhost:46239/blog/cpu_cache/singlecore-caching/single-multi-core-deepseek/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>http://localhost:46239/blog/cpu_cache/singlecore-caching/single-multi-core-deepseek/</guid>
      <description>&lt;p&gt;New chat&#xA;Please review the article for correctness &amp;ldquo;## &lt;strong&gt;Cache Coherence and Protocols: Ensuring Data Consistency in Multi-Core Systems&lt;/strong&gt;&#xA;Modern multi -  core processors rely on private caches to reduce latency and improve performance.However, when multiple cores access the same memory location, ensuring consistency across caches becomes essential. &lt;strong&gt;Cache coherence&lt;/strong&gt; guarantees that all cores observe a consistent view of memory, preventing stale or incorrect data from affecting computations.&lt;/p&gt;&#xA;&lt;p&gt;This article explores why cache coherence is crucial, common problems that arise without it,and how protocols address these issues.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
